#!/bin/ksh
## Project:
#SBATCH --account=nn9385k
## Job name:
#SBATCH --job-name=f05_mpi
#SBATCH --output=r_f05_mpi_out_%j
## Wall time limit:
#SBATCH --time=0-0:80:0
## Number of nodes and Number of tasks to start on each node:
#SBATCH --nodes=10 --ntasks-per-node=32
## Set OMP_NUM_THREADS
##SBATCH --cpus-per-task=16

###############################################################################
#                              historical_r1i1p1-LR.run
#   Automatically generated by Create_TASKS.frm using the m4 macro processor.
###############################################################################
#
#   R U N - Script for the model configuration mpiesm-asob
#
#   coupled model configuration with the components
#      ECHAM - global atmosphere GCM (MPI-HH)
#      JSBACH - global land surface model (MPI-HH)
#      MPIOM  - global ocean GCM (MPI-HH)
#      HAMOCC - global ocean bio-geo-chemistry model (MPI-HH)
#
###############################################################################
###############################################################################

set -ex
export task=RUN     # The task: RUN, ARCH, POST, MON, REM
print "\n Start of script at\t$(date)\n - on host or node\t$(hostname)"

#mail -s "`date`: finally running ..." earnestshen@gmail.com <<< 'as title ...'
#------------------------------------------------------------------------------
#        SETUP OF EXPERIMENT
#------------------------------------------------------------------------------

#
#-- Project ID
#

export proid=c5_
export groupwrite=no

#
#-- Experiment ID
#

export expid=f05_1AGCM 
export parent_experiment="piControl"                                      # CMOR CV
export parent_member="r1i1p1"                                             # CMOR CV
export parent_branch_time=18500101,18791231
export forcing_text="GHG Oz SD Sl Vl LU"                                  # CMOR CV

#
#-- Coupled model name
#

export cplmod=mpiesm-asob

#
#-- Node name / OS of the computing host
#

export node=hexagon

#
#-- components
#

atmmod=echam6
srfmod=jsbach
ocemod=mpiom
bgcmod=hamocc
coupler=oasis3

###############################################################################
#
#     USER INTERFACE
#
###############################################################################

export verbose=no                # yes/no 

#------------------------------------------------------------------------------
#   Configuration of component(s)
#------------------------------------------------------------------------------

#
#-- ECHAM
#
res_atm=T63                 # grid acronym (T21/T31/T42/T63/T85/T106/T127/T159)
vres_atm=47                 # number of vertical levels
atmvers=c170901o2          # model version (used in executable name)
dt_write_atm=24              # time interval of output writing in hours
lco2=false                  # true: prognostic CO2 mass mixing ratio
nml_suf_echam=historical-LR # namelist file name suffix (in adjunct_files)
atm_out_filetype=1          # output file format: 1=GRIB (def) / 2=NETCDF
atm_out_ztype=0             # file compression: 0=NONE/1=GRIB SZIP (def)/2=ZIP
atm_restart_filetype=4      # restart file format: 4=NETCDF (def)
#iaero=5                     # time dependent aerosol forcing (3) incl.volcanic(5)
io3=4                       # time dependent ozone forcing
ico2=2
iaero=3                      # 3: time dependent aerosols; 5: incl.volcanic
isolrad=2
#icfc=4
#ich4=4
#in2o=4

nhd_diag=1
lcouple_co2=true
COSP=false                   # cosp diagnostic is switched of in mpiesm-1.0.00 
#
#-- JSBACH
#
dynveg=true                  # calculate dynamic vegetation (true/false)
dynveg_feedback=true         # feedback of dyn. vegetation on climate activated
ntiles=11                    # number of tiles
read_cpools=false            # read cpools file at start of initialized exp
lcc_forcing_type=transitions # Scheme for landuse change (none, maps, transitions)
read_fpc=false               # true:read frac. plant cover file at exp start
refyear=1850                 # reference year of initial data (e.g. cpools)
nml_suf_jsbach=c5            # namelist file name suffix (in adjunct_files) 
srf_out_filetype=GRIB        # output file format: GRIB (def) / NETCDF
srf_restart_filetype=NETCDF  # restart file format: NETCDF
lctlibvers=nlct21.def
transition_scenario=historical # landuse transition scenario (only with
                               #      lcc_forcing_type=transitions)
                               #      historical / rcp45 / rcp85 / rcp26 / no
                               #      no: no transitions, harvest from refyear

#
#-- MPIOM
#
res_oce=GR15             # grid acronym (GR30/GR15/TP10/TP04/TP01)
vres_oce=40              # number of vertical levels
nml_suf_mpiom=c5-LR      # namelist file name suffix (in adjunct_files)
nfixYearLen=-1           #
istart=3                 # start experiment from Levitus climatology
oce_out_filetype=nc      # format of model output (sz/grb/ex/nc)
oce_restart_filetype=nc  # format of model restart file (ex/nc)
ocevers=c170901o2

#
#-- HAMOCC
#
nml_suf_hamocc=c5-LR     # tag for namelist (in adjunct_files) 

#
#-- if unexplained crashes; for different: 
#       - change value of enstdif (e.g. 1.0001) (ECHAM6 namelist dynctl)
#       - add lines if necessary but do not remove !
#
set_enstdif="[[ \$(echo \${startdate} | cut -c1-4) = YYYY ]] && enstdif=1.0001"


cplversion=c170901o2
#-- Executable name as stored in .../bin


ocebin=${ocemod}_${bgcmod}_${ocevers}.x
atmbin=${atmmod}_${atmvers}.x
cplbin=${coupler}_${cplversion}.x

#------------------------------------------------------------------------------
# End of component configuration
#------------------------------------------------------------------------------

#
#-- COUPLER
#
jobname=c5_             # OASIS experiment-id (3 characters)
nlogprt=0               # Standard output extent:
                        #    0: little
                        #    1: much
                        #    2: very much std. output

run_mode=concurrent     # sequential / concurrent (=parallel)

# remapping parameters

scripwr=0               # writing of SCRIP remapping matrices
                        #  0: use SCRIP matrice if exists; else (re)calculation
                        #  1: unconditional (re)calculation of SCRIP matrices

gridswr=0               # writing of grid description files for OASIS   
                        #  0: use grid descr. files if exist; else (re)generation
                        #  1: unconditional (re)generation of grid descr. files

extrapwr=0              # writing of extrapolation matrix (NINENN)
                        #   0: use of existing extrapolation matrix 
                        #      (error if not available)
                        #   1: unconditional (re)generation of the extrap. matrix
                        #  Note: if gridswr=1 extrapwr needs to be 1 too

FV_cpl=_frac            #

# time interval of data exchange or coupling time step 

dto2a=86400             # time step from ocean to atmosphere (86400/43200) [s]
                        # Note: time step from atmosphere to ocean is 86400 s

# treatment of coupling fields (see OASIS documentation for more information)

timtranso2a=INSTANT     # INSTANT / AVERAGE
export=EXPORTED         # EXPORTED / EXPOUT


#------------------------------------------------------------------------------
#   TIME CONTROL
#------------------------------------------------------------------------------

#
#-- calendar type: Available calendar options:
#     0   : No leap year (365 days per year)
#     1   : Gregorian (365/366 days per year)
#     n   : Equal months of "n" days (30 for 30 day months)

caltype=1

#
#-- initial and final date of the experiment
#   Format: YearMMDD[_hh[mm[ss]]], Year-MM-DD[_hh[:mm[:ss]]] or 
#           Year-MM-DD[Thh[:mm[:ss]]]
#   Note: The experiment will not stop within a run/chunk even if the
#         final date is reached.

ReferYear=1980
initial_date=1850-01-01   # initial exp. date
final_date=2400-12-31   # final date of the experiment

#
#-- duration of a run/chunk
#      Specify the length of each run in one of the below units.

#integer nyear nmonth nday nhour nminute nsecond

nyear=1          # number of years per run
nmonth=0         # number of months per run
nday=0           # number of days per run
nhour=0          # number of hours per run
nminute=0        # number of minutes per run
nsecond=0        # number of seconds per run
nstep_atm=0      # number of atmosphere model time steps per run
nstep_oce=0      # number of ocean model time steps per run


#------------------------------------------------------------------------------
#   1.4 INITIAL SETTINGS
#------------------------------------------------------------------------------

#
#-- file and directory permissions of the output
#

export dir_permits=755
export file_permits=644

#------------------------------------------------------------------------------
#   MESSAGE PASSING
#------------------------------------------------------------------------------

#
#-- number of MPI-processors/openMP-threads
#

#integer nproca_oce nprocb_oce nthreadoce
#integer nproca_atm nprocb_atm nproma_atm nthreadatm
#integer nprocoasis

#nproca_atm=20  # total number of MPI procs: 
#nprocb_atm=16  #      nproca_atm*nprocb_atm
#nthreadatm=1   # number of openMP threads (overwrites OMP_NUM_THREADS)
#nproma_atm=72

#nproca_oce=16  # total number of MPI procs:
#nprocb_oce=10   #      nproca_oce*nprocb_oce
#nthreadoce=1   # number of openMP threads (overwrites OMP_NUM_THREADS) 

nproca_atm=16  # total number of MPI procs: 
nprocb_atm=11  #      nproca_atm*nprocb_atm
nthreadatm=1   # number of openMP threads (overwrites OMP_NUM_THREADS)
nproma_atm=72

nproca_oce=13  # total number of MPI procs:
nprocb_oce=11   #      nproca_oce*nprocb_oce
nthreadoce=1   # number of openMP threads (overwrites OMP_NUM_THREADS) 

nprocoasis=1   # number of processors dedicated for OASIS (1/0)

#
#-- launching mode (spawned by coupler: MPI2; MPI1 otherwise)
#

message_passing=MPI1

#
#-- buffered MPI Send 
#      yes: buffered send
#       no: simple send

bsend=no

#------------------------------------------------------------------------------
#   MPI MESSAGE PASSING SPECIFICATIONS
#------------------------------------------------------------------------------

#MSL# need check
MPIBIN=$(which srun)  


#
#-- number of processors used for the mpiexec
# 
#integer nprocmpi

nprocmpi=0

#------------------------------------------------------------------------------
#   CONNECTION TO COMPILE SYSTEM
#------------------------------------------------------------------------------

#
#-- name of compiler (set according to Create_TASKS parameter specifications)

compiler=intel

#
#-- (symbolic) node name of the compile-server

compile_server=fram

#------------------------------------------------------------------------------
#   FILE SYSTEMS
#------------------------------------------------------------------------------
#
#-- home:  Permanent file system for the SCRIPTS on the COMPUTING HOST
#          (only needs to be specified if the tasks are NOT generated on the 
#          computing host)

workhome=/cluster/work/users/earnest/mpiexm_exp
export home=${workhome}

#
#-- archive_in:  Root directory of the LONG TERM INPUT data archive. It needs
#                to reside on the same machine as the output archive. This 
#                archive is intended for input data that is needed with 
#                several experiments, e.g. initial , forcing or restart files.
#                The parent-directory needs to exist before job submission.

export archive_in=${workhome}/restart_historical_mpiesm

#
#-- data:  Root directory of the SHORT TERM data server.
#          Model INPUT and OUTPUT will be read from/written to 
#          this file system of the computing host
#          The parent-directory needs to exist before job submission.

export data=${workhome}

#
#-- archive:  Root directory of the LONG TERM OUTPUT data archive:
#             a filesystem of the computing or of the remote archiving host. 
#             If ${archive} differs from ${data} model output will be saved
#             in ${archive} and removed from ${data}.
#             The parent-directory needs to exist before job submission.

export archive=${workhome}

#
#-- work:  Root directory for the temporary working directory
#             (for production runs use $TMPDIR on NEC)
#

work=${workhome}

#
#-- Path to the IMDI function directory
#
export fpath=/nird/home/earnest/models/MPI-ESM/mpiesm-1.0.01/Sources/util/running/functions

#
#-- <modelcomp>_bindir:   Directory of the model executables.
#
compile_path=/nird/home/earnest/models/MPI-ESM/mpiesm-1.0.01/Sources/fram-intel/bin
 
export atm_bindir=${compile_path}
export oce_bindir=${atm_bindir}
export cpl_bindir=${atm_bindir}

#------------------------------------------------------------------------------
#   1.7 RESTART CONTROL
#------------------------------------------------------------------------------ 

#
#-- 'component'_restart: start from restart or initial files (climatology)
#         1  : start experiment from restart files for 'component'
#         0  : start experiment from initial conditions for 'component'
#      If the experiment starts from restart files you need to specify:
# 
#   'component'_age: the age of the restart file used in years
#   'component'_restart_file: filename of the restart file (including path)
#

odate=18791231; ndate="-18491231"                   # separate with hyphen
pexp=piControl_r1i1p1-LR

atm_restart=1; atm_age=0
atm_restart_dir=${archive_in}/input/${atmmod}/${res_atm}/restart
atm_restart_file=${atm_restart_dir}/rerun_${pexp}_echam_${odate}${ndate}
atm_restart_co2=${atm_restart_dir}/rerun_${pexp}_co2_${odate}${ndate}
atm_restart_tracer=""

hd_name=rerun_${pexp}_hd
hd_restart_dir=${archive_in}/input/hd/${res_atm}/restart
hd_restart_file=${hd_restart_dir}/${hd_name}_${odate}${ndate}.nc

srf_restart=${atm_restart}
srf_restart_dir=${archive_in}/input/${srfmod}/${res_atm}/restart
srf_restart_jsbach=${srf_restart_dir}/rerun_${pexp}_jsbach_${odate}${ndate}
srf_restart_surf=${srf_restart_dir}/rerun_${pexp}_surf_${odate}${ndate}
srf_restart_veg=${srf_restart_dir}/rerun_${pexp}_veg_${odate}${ndate}

oce_restart=1; oce_age=0
oce_restart_dir=${archive_in}/input/${ocemod}/${res_oce}/restart
oce_restart_file=${oce_restart_dir}/rerun_${pexp}_mpiom_${odate}${ndate}.nc

bgc_restart=1; bgc_age=0 
bgc_restart_dir=${archive_in}/input/${bgcmod}/${res_oce}/restart
bgc_restart_file=${bgc_restart_dir}/rerun_${pexp}_hamocc_${odate}${ndate}.nc

cpl_restart=1
cpl_restart_dir=${archive_in}/input/${coupler}/restart
cpl_restart_file_sstocean=${cpl_restart_dir}/sstocean_${pexp}_${odate}${ndate}.tar
cpl_restart_file_flxatmos=${cpl_restart_dir}/flxatmos_${pexp}_${odate}${ndate}.tar


#------------------------------------------------------------------------------
#   PLATFORM DEPENDEND SPECIFICATIONS
#------------------------------------------------------------------------------

#
#-- Node name of archiving host  (empty if archiving on local file system)
#
export archiving_host=$HOST_ARCH       #  pftp on the DKRZ HPSS archive

#------------------------------------------------------------------------------
#   UNIX COMMANDS
#------------------------------------------------------------------------------

export mkdir="mkdir -p"    # create a new directory
export cp="cp -p"          # copy without changing the time stamp
export ln="ln -s"          # sym/hard link: no err/err if non-existing target
export rm=rm               # remove
export rtp="pftp"          # remote transfer protocol
export rtp_post="$rtp"     # transfer protocol to remote processing host
export put_archive=""      # command to put files to tape archive (e.g. dsmc)
export get_archive=""      # command to get files from tape archive (e.g. dsmc)
export gunzip="gzip -d"    # unzip a file that was zipped using gzip


export cdo=$(which cdo)        # climate data operator
export python=$(which python)  # python


export afterburner=/home/uib/earnest/tools/after
export ncdump=$(which ncdump)
export nco=/work/apps/nco/4.5.0-ncap2-gnu/bin


#------------------------------------------------------------------------------
#   CONFIGURE MODEL INPUT
#------------------------------------------------------------------------------

#
#-- specify input files for ECHAM
#

aip=${archive_in}/input/${atmmod}
aipr=${archive_in}/input/${atmmod}/${res_atm}

atm_ifiles="\
get_file ${atmmod} input ${aipr}/${res_atm}\${res_oce}_VGRATCLIM.nc  unit.91;\
get_file ${atmmod} input ${aipr}/${res_atm}\${res_oce}_VLTCLIM.nc    unit.90;\
get_file ${atmmod} input ${aipr}/${res_atm}_TSLCLIM2.nc              unit.92;\
get_file ${atmmod} input ${aipr}/${res_atm}L${vres_atm}_jan_spec.nc  unit.23;\
get_file ${atmmod} input ${aipr}/${res_atm}\${res_oce}_jan_surf.nc   unit.24"

atm_ifiles=${atm_ifiles}";\
get_file ${atmmod} input  ${aip}/surrta_data                        rrtadata;\
get_file ${atmmod} input  ${aip}/rrtmg_lw.nc                     rrtmg_lw.nc;\
get_file ${atmmod} input  ${aip}/ECHAM6_CldOptProps.nc ECHAM6_CldOptProps.nc"

ozonedir=${archive_in}/input/${atmmod}/${res_atm}/ozone2
atm_ifiles=${atm_ifiles}";\
get_file ${atmmod} input ${ozonedir}/${res_atm}_ozone_CMIP5_\${ReferYear}.nc ozon\${ym2};\
get_file ${atmmod} input ${ozonedir}/${res_atm}_ozone_CMIP5_\${ReferYear}.nc ozon\${ym1};\
get_file ${atmmod} input ${ozonedir}/${res_atm}_ozone_CMIP5_\${ReferYear}.nc ozon\${yr0};\
get_file ${atmmod} input ${ozonedir}/${res_atm}_ozone_CMIP5_\${ReferYear}.nc ozon\${yp1}"

aerodir=${archive_in}/input/${atmmod}/${res_atm}/aero2
atm_ifiles=${atm_ifiles}";\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_sw_b14_fin_\${ReferYear}.nc aero_fine_\${ym2}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_sw_b14_fin_\${ReferYear}.nc aero_fine_\${ym1}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_sw_b14_fin_\${ReferYear}.nc aero_fine_\${yr0}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_sw_b14_fin_\${ReferYear}.nc aero_fine_\${yp1}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_sw_b14_coa.nc       aero_coarse_\${ym2}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_sw_b14_coa.nc       aero_coarse_\${ym1}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_sw_b14_coa.nc       aero_coarse_\${yr0}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_sw_b14_coa.nc       aero_coarse_\${yp1}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_lw_b16_coa.nc        aero_farir_\${ym2}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_lw_b16_coa.nc        aero_farir_\${ym1}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_lw_b16_coa.nc        aero_farir_\${yr0}.nc;\
get_file ${atmmod} input ${aerodir}/${res_atm}_aeropt_kinne_lw_b16_coa.nc        aero_farir_\${yp1}.nc"

vaerodir=${archive_in}/input/${atmmod}/${res_atm}/volcano_aerosols
atm_ifiles=${atm_ifiles}"; \
get_file ${atmmod} input ${vaerodir}/strat_aerosol_ir_${res_atm}_\${ReferYear}.nc strat_aerosol_ir_\${ym2}.nc;\
get_file ${atmmod} input ${vaerodir}/strat_aerosol_ir_${res_atm}_\${ReferYear}.nc strat_aerosol_ir_\${ym1}.nc;\
get_file ${atmmod} input ${vaerodir}/strat_aerosol_ir_${res_atm}_\${ReferYear}.nc strat_aerosol_ir_\${yr0}.nc;\
get_file ${atmmod} input ${vaerodir}/strat_aerosol_ir_${res_atm}_\${ReferYear}.nc strat_aerosol_ir_\${yp1}.nc;\
get_file ${atmmod} input ${vaerodir}/strat_aerosol_sw_${res_atm}_\${ReferYear}.nc strat_aerosol_sw_\${ym2}.nc;\
get_file ${atmmod} input ${vaerodir}/strat_aerosol_sw_${res_atm}_\${ReferYear}.nc strat_aerosol_sw_\${ym1}.nc;\
get_file ${atmmod} input ${vaerodir}/strat_aerosol_sw_${res_atm}_\${ReferYear}.nc strat_aerosol_sw_\${yr0}.nc;\
get_file ${atmmod} input ${vaerodir}/strat_aerosol_sw_${res_atm}_\${ReferYear}.nc strat_aerosol_sw_\${yp1}.nc"

irraddir=${archive_in}/input/${atmmod}/solar_irradiance
atm_ifiles=${atm_ifiles}";\
get_file ${atmmod} input ${irraddir}/swflux_14band_\${ReferYear}.nc   swflux_\${ym2}.nc;\
get_file ${atmmod} input ${irraddir}/swflux_14band_\${ReferYear}.nc   swflux_\${ym1}.nc;\
get_file ${atmmod} input ${irraddir}/swflux_14band_\${ReferYear}.nc   swflux_\${yr0}.nc;\
get_file ${atmmod} input ${irraddir}/swflux_14band_\${ReferYear}.nc   swflux_\${yp1}.nc"

atm_ifiles=${atm_ifiles}";\
get_file ${atmmod} input ${aip}/greenhouse_rcp45.nc greenhouse_gases.nc"

hip=${archive_in}/input/hd
atm_ifiles=${atm_ifiles}";\
get_file ${atmmod} input ${hip}/hdpara.nc                        hdpara.nc;\
get_file ${atmmod} input ${hip}/hdstart.nc                      hdstart.nc"

#
#-- specify input files JSBACH
#

grid=${res_atm}${res_oce}_${ntiles}tiles
sip=${archive_in}/input/${srfmod}
sipr=${sip}/\${res_srf}

srf_ifiles="\
get_file ${srfmod} input lctlib_${lctlibvers}                   lctlib.def;\
get_file ${srfmod} input ${sipr}/jsbach_${grid}_${refyear}.nc   jsbach.nc"

ludir=${archive_in}/input/${srfmod}/\${res_srf}/land_use
srf_ifiles=${srf_ifiles}";\
get_file ${srfmod} input ${ludir}/LUH_transitions_\${res_srf}_\${ReferYear}.nc landuseTransitions.\${yr0}.nc;\
get_file ${srfmod} input ${ludir}/LUH_transitions_\${res_srf}_\${ReferYear}.nc landuseTransitions.\${ym1}.nc;\
get_file ${srfmod} input ${ludir}/LUH_harvest_\${res_srf}_\${ReferYear}.nc         landuseHarvest.\${yr0}.nc;\
get_file ${srfmod} input ${ludir}/LUH_harvest_\${res_srf}_\${ReferYear}.nc         landuseHarvest.\${ym1}.nc"

#
#-- specify input files for MPIOM
#

oipr=${archive_in}/input/${ocemod}/${res_oce}

oce_ifiles="\
cp                       ${oipr}/${res_oce}_BEK BEK;        chmod 775 BEK;\
get_file ${ocemod} input ${oipr}/${res_oce}_anta                     anta;\
get_file ${ocemod} input ${oipr}/${res_oce}_arcgri                 arcgri;\
get_file ${ocemod} input ${oipr}/${res_oce}_topo                           topo"

#
#-- specify input files for HAMOCC
#

bip=${archive_in}/input/${bgcmod}
bipr=${archive_in}/input/${bgcmod}/\${res_bgc}

bgc_ifiles="\
get_file ${bgcmod} input ${bipr}/\${res_bgc}_MAHOWALDDUST.nc INPDUST.nc"

#
#-- configurable input files for OASIS3
#

cplinpdir=${archive_in}/input/${coupler}/

cpl_ifiles="\
get_file         ${coupler} input                      cf_name_table.txt;\
get_file -nolink ${coupler} input  namcouple_${cplmod}         namcouple"

###############################################################################
#
#      END OF THE USER INTERFACE
#
###############################################################################


set -e
#------------------------------------------------------------------------------
#  Complete setup 
#------------------------------------------------------------------------------

#
#-- get CMIP5 MPI-ESM model acronym
#
res_mod=$(echo $expid | cut -f2 -d"-")

#
#-- coupling
#
timtransa2o=INSTANT

dta2o=86400

#
#-- JSBACH
#
srf_restart=${atm_restart}
res_srf=${res_atm}
[[ ! "$srf_out_ztype" = "" ]] || srf_out_ztype="${atm_out_ztype}"

#
#-- hydrology
#
hd=true

#
#-- MPIOM
#
nx_oce=256
ny_oce=220
nodt=4320

#
#-- HAMOCC
#
res_bgc=${res_oce}
nbdt=${nodt}

#
#-- ECHAM
#
[[ ${res_atm} = T31 ]] && isolrad=1       #isolrad=0 not possible with T31
nadt=600

#
#-- Executable name for launching etc.
#
oceexec=${ocemod}
atmexec=${atmmod}
cplexec=oasis.x

atm_src_revision=$(echo $atmbin | cut -f3 -d"_" | cut -c2-5)
oce_src_revision=$(echo $ocebin | cut -f4 -d"_" | cut -c2-5)

#
# Number of MPI-processors/openMP-threads
# ---------------------------------------

#integer ntproc nprocatm nprococe ncplprocatm ncplprococe

ncplprococe=1  # number of ocean MPI processes communicating with oasis
ncplprocatm=1  # number of atmosphere MPI processes communicating with oasis

(( nprocatm = nproca_atm * nprocb_atm ))  # total number of atm. MPI processes
(( nprococe = nproca_oce * nprocb_oce ))  # total number of ocean MPI processes

# total number of MPI processes
ntproc=nprocatm+nprococe+nprocmpi+nprocoasis

#------------------------------------------------------------------------------
#   Definition of the functions 
#------------------------------------------------------------------------------

export PATH=${fpath}:$PATH 

. function_check_size
. function_check_codes
. function_dbfill
. function_generate_tarfile
. function_get_file
. function_get_model_resolution
. function_get_tarfile
. function_make_directories
. function_put_file
. function_plot_file
. function_pperror

#------------------------------------------------------------------------------
#   Job specification
#------------------------------------------------------------------------------

qsub="qsub"        # submit command

if [ "${qsub}" = "qsub" ]; then
  jobdir=${home}/${expid}/scripts       # directory of this script
  cd ${jobdir}
  jobid=${expid}
  job=${jobid}.run
else
  jobdir=`dirname $0`
  cd ${jobdir}
  jobdir=`pwd`
  jobid=${expid}
  job=`basename $0`
fi


echo " - job name         \t${job}"
echo " - job id           \t${jobid}\n - job directory    \t${jobdir}\n"


#------------------------------------------------------------------------------
#
#     3. CALENDAR
#
#------------------------------------------------------------------------------
#
#-- calculate length of the run in seconds for the case that (optionally)
#   the length of run is given in number of model steps of any of the models.
#
if   [ "${nstep_atm}" -ne 0 ] && [ "${nstep_atm}" -ne "" ]; then
  (( nsecond = nstep_atm * nadt ))
elif [ "${nstep_oce}" -ne 0 ] && [ "${nstep_oce}" -ne "" ]; then
  (( nsecond = nstep_oce * nodt ))
elif [ "${nstep_che}" -ne 0 ] && [ "${nstep_che}" -ne "" ]; then
  (( nsecond = nstep_che * ncdt ))
elif [ "${nstep_srf}" -ne 0 ] && [ "${nstep_srf}" -ne "" ]; then
  (( nsecond = nstep_srf * nsdt ))
fi

#
#-- find out smallest time unit in inidate and job length
#
inidate=`format_date -- ${initial_date}`   # transform to format (YearMMDD_hhmmss)
findate=`format_date -- ${final_date}`

nwords=$(format_date -f4 -- ${inidate} | wc -w) 
if [ ${nwords} -eq 6 ] || [ ${nsecond} -ne 0 ]; then
  inidate=$(format_date -s -- ${inidate})
  findate=$(format_date -s -- ${final_date})
elif [ ${nwords} -eq 5 ] || [ ${nminute} -ne 0 ]; then
  inidate=$(format_date -m -- ${inidate})
  findate=$(format_date -m -- ${final_date})
elif [ ${nwords} -eq 4 ] || [ ${nhour} -ne 0 ]; then
  inidate=$(format_date -h  -- ${inidate})
  findate=$(format_date -h  -- ${final_date})
fi

#
#-- date of this run
#

cd ${jobdir}
space_error="no"

datefmt='%a %b %d %H:%M:%S %Z %Y'  # date format for expid.log file

if [ ! -f ${expid}.date ]; then

  startdate=${inidate}
  jobnum=1
  rm -f ${expid}.log
  echo "$(date +"${datefmt}") :  Beginning of Experiment ${expid}" > ${expid}.log.new || { 
      space_error="yes"; echo "Could not create ${expid}.log"; 
  }
else
  read startdate jobnum < ${expid}.date
  cp ${expid}.log ${expid}.log.new || { 
    space_error="yes"; echo "Could not save ${expid}.log"; 
  }
fi

echo "$(date +"${datefmt}") :  ${jobnum} ${startdate} ${jobid}  - start" >> ${expid}.log.new || { 
  space_error="yes"; echo "Could not append to ${expid}.log"; 
}
if [ "${space_error}" = "no" ]; then
  mv ${expid}.log.new ${expid}.log
else
  echo "  |- ERROR: No disk space left or quota exceeded?"
  exit 1
fi

integer scrcap
line=$(df -k $data | tail -1)
scrfs=${line##* }
line=${line%%\%*} ;scrcap=${line##* }

if (( scrcap > 99 )); then
  echo "  |- ERROR: Less than 1% disc space left on filesystem $scrfs, where your"
  echo "  |    workshare data=$data is mounted. Please clean up before you continue !"
  exit 1
fi

nextdate=$(calc_date plus -c${caltype} -Y${nyear} -M${nmonth} -D${nday} -h${nhour} -m${nminute} -s${nsecond} -- ${startdate})

echo " |+ Time integration and run periode"
echo "  |- Initial date of the experiment\t${inidate}"
echo "  |- Final date of the experiment\t${findate}"
echo "   |- Beginning of this run    \t ${startdate}"
echo "   |- Beginning of the next run\t ${nextdate}\n"

#------------------------------------------------------------------------------
#   Directory definitions
#------------------------------------------------------------------------------

exphome=${data}/${expid}          # Root directory of the experiment (data)

[ ${host_rem:-NotSet} = NotSet ] || {
  if [ "$(hostname)" = "${host_rem%%.*}" ] ; then 
   exphome=${path_rem:-""}/${expid}   # the above, if processing is remote
  fi
  }
export bindir=${archive}/${expid}/bin      # Directory of the executables
mkdir -p ${bindir}
cp -rfv ${compile_path}/*${atmvers}*  ${bindir}                #   */
export inpdir=${exphome}/input    # Directory of the input files
export restdir=${archive}/${expid}/restart # Directory of the restart files
export outdir=${archive}/${expid}/outdata  # Directory of the output data files
export logdir=${archive}/${expid}/log      # Directory of the log data files
export postdir=${archive}/${expid}/post    # Directory for post-processed data

if [ ${jobnum} = 1 ];then
  make_directories $task "${atmmod},${srfmod},${ocemod},${bgcmod},${coupler}"
  if [ "${task}" = "RUN" ]; then
    [[ "${groupwrite:-no}" = "no" ]] || {
       chmod g+wx ${data} ${exphome} ${bindir} ${inpdir} ${logdir}       \
         ${restdir} ${restdir}/${atmmod} ${restdir}/${srfmod}            \
         ${restdir}/${ocemod} ${restdir}/${bgcmod} ${restdir}/${coupler} \
         ${outdir} ${outdir}/${atmmod} ${outdir}/${srfmod}               \
         ${outdir}/${ocemod} ${outdir}/${bgcmod} ${outdir}/${coupler} || true; }
  fi
fi

#------------------------------------------------------------------------------
#
#     save log file of the previous run
#
#------------------------------------------------------------------------------


if [ ${jobnum} != 1 ]; then
    # find out the id of the last run
    loginfo=$(get_logpid -d ${startdate} -f ${jobdir}/${expid}.log)                
    previd=${loginfo%[ ]*}
    if [ "${previd}" = "${expid}" ] || [ -z "${previd}" ]; then 
      printf "\t|- WARNING : Job id of the previous run can not determined."
      printf "\t|    Job maybe interactively submitted.\n"
    else
	date=${loginfo#*[ ]}
        logfile=my_${job}.o${previd}
	if [ ! -f ${jobdir}/${logfile} ] && \
           [ ! -f ${logdir}/${job}_${date}.o${previd} ]; then
	  printf "\tAwaiting the log file of the previous run: ${logfile}...\n"
	  sleep 30
	fi
	if [ -f ${jobdir}/${logfile} ]; then
	    mv ${jobdir}/${logfile} ${logdir}/${job}_${date}.o${previd}

        elif [ ! -f ${logdir}/${job}_${date}.o${previd} ]; then
            printf "\t%s%s\n" "WARNING : No logfile of the previous run " \
                   "(job no $(( jobnum - 1 )) ) - continue"
        fi
    fi
fi

#------------------------------------------------------------------------------
#   PRE - PROCESSING : check working directory, clean, and cd
#------------------------------------------------------------------------------

cd ${work}

[[ -d ${expid}/work ]] || mkdir -p ${expid}/work
[[ "${groupwrite:-no}" = "no" ]] ||  {  
 chmod g+wx  ${expid}/work || true; }

cd ${expid}/work;  rm -rf *

printf "\n |- Temporary working directory     \t$(pwd)\n"
printf   " |- Data workshare on compute node  \t$data/$expid\n\n"

#------------------------------------------------------------------------------
#     PRE - PROCESSING : Provide the executables
#------------------------------------------------------------------------------

#
# for CMIP5 experiments the executables are taken from ${<modelcomp>_bindir}/bin
#

${ln} ${bindir}/${atmbin} ${atmexec}
${ln} ${bindir}/${ocebin} ${oceexec}
${ln} ${bindir}/${cplbin} ${cplexec}
#------------------------------------------------------------------------------
#     PRE - PROCESSING : provide the input data 
#------------------------------------------------------------------------------

printf " |- Get input and restart data\n"

#------------------------------------------------------------------------------
#-- get input files for the coupler (OASIS3)
#------------------------------------------------------------------------------

eval       ${cpl_ifiles}

#-- grid and analysis auxiliary input files for OASIS3
#

n=0
while (( n < ${nprocoasis} )); do

[[ ${nprocoasis} = 1 && $jobnum = 1 ]] && Opt="-opt" 
  if [ $scripwr = 0 ]; then
    fconst=CONSERV_FRACAREA
    res_tag=${res_atm}_${res_oce}${input_tag}
    get_file ${Opt:-""} ${coupler} input  \
             ${cplinpdir:-""}rmp_oces_to_atmo_${fconst}_${res_tag}.nc \
             rmp_oces_to_atmo_${fconst}_${n}.nc
    get_file ${Opt:-""} ${coupler} input  \
             ${cplinpdir:-""}rmp_atmo_to_oces_${fconst}_${res_tag}.nc \
             rmp_atmo_to_oces_${fconst}_${n}.nc
    get_file ${Opt:-""} ${coupler} input  \
             ${cplinpdir:-""}rmp_atml_to_oces_${fconst}_${res_tag}.nc \
             rmp_atml_to_oces_${fconst}_${n}.nc
  fi
  if [ "${gausswr:-""}" = "0" ] ; then
   get_file ${Opt} ${coupler} input  \
            ${cplinpdir:-""}gweights_${res_atm}_${res_oce}${FV_cpl} gweights_${n}
  fi
  if [ "${meshwr:-""}" = "0" ] ; then
   get_file ${Opt:-""} ${coupler} input  \
            ${cplinpdir:-""}mweights_${res_atm}_${res_oce}${FV_cpl} mweights_${n}
  fi
  get_file ${Opt:-""} ${coupler} input  \
            ${cplinpdir:-""}nweights_${res_atm}_${res_oce}${FV_cpl}${input_tag} \
            nweights_${n} 
  if [[ ${res_mod} = MR ]];then
  get_file ${Opt:-""} ${coupler} input  \
            ${cplinpdir:-""}rmp_atmo_to_oces_BICUBIC_${res_tag}.nc \
             rmp_atmo_to_oces_BICUBIC_${n}.nc 
  fi
  (( n = n + 1 ))
done

if [[ $gridswr = 0 ]]; then
  get_file ${Opt:-""}  ${coupler}  input  \
           ${cplinpdir:-""}grids_${res_atm}_${res_oce}${FV_cpl}.nc grids.nc
  get_file ${Opt:-""}  ${coupler}  input  \
           ${cplinpdir:-""}areas_${res_atm}_${res_oce}${FV_cpl}${input_tag}.nc areas.nc
  get_file ${Opt:-""}  ${coupler}  input  \
           ${cplinpdir:-""}masks_${res_atm}_${res_oce}${FV_cpl}${input_tag}.nc masks.nc
fi

#-- restart files
#

prevdate=`calc_date minus -c${caltype} -D1 -- ${startdate}`
if [ ${jobnum} = 1 ]; then
  if [ ${cpl_restart} = 1 ]; then
    if [ ${run_mode} = concurrent ]; then
      \cp  ${cpl_restart_file_flxatmos}   flxatmos.tar     
      tar -xvf flxatmos.tar; rm flxatmos.tar
    fi
    \cp  ${cpl_restart_file_sstocean}  sstocean.tar
    tar -xvf sstocean.tar; rm sstocean.tar
  fi
else
  if [ ${run_mode} = concurrent ]; then
    get_file ${coupler} restart flxatmos_${expid}_${prevdate}.tar flxatmos.tar
    tar -xf flxatmos.tar; rm flxatmos.tar
  fi
  get_file ${coupler} restart sstocean_${expid}_${prevdate}.tar sstocean.tar
  tar -xf sstocean.tar; rm sstocean.tar
fi

#
#-- input files for ECHAM
#

typeset -Z4 yr0 yp1 ym1 ym2
yr0=$(echo ${startdate} | cut -c1-4)
(( yp1 = yr0 + 1 )); (( ym1 = yr0 - 1 )); (( ym2 = yr0 - 2 ))

eval ${atm_ifiles}


#-- (de)activate simulator output (isccp etc.) according to CMIP5/CFMIP request
#   note: care must be taken that the year before has been
#         run with locosp=T if locosp=true below. This may be a problem when
#         the restart files are generated by another experiment.
#   off: difference [years] between start year of piControl and 1pctCO2 (or abrupt4xCO2)
#
. c5_cosp_request
c5_cosp_request $(echo ${startdate} | cut -c1-4) $expid locosp ${off:-""}
prevdate=`calc_date minus -c${caltype} -D1 -- ${startdate}`
prevyear=$(format_date -f4 -- ${prevdate} | cut -f1 -d" ")
c5_cosp_request $prevyear                        $expid locosp_prev ${off:-0}

#-- No COSP files generated for model revisions less than 4871
[[ "${atm_src_revision}" -ge 4871 ]] || locosp=false

#-- No COSP files generated for mpiesm-1.0.00
if [[ "${COSP}" = false ]]; then
  locosp=false
fi



#-- COSP restart files have to be generated with locosp=T

[[ $locosp = true && ${jobnum} = 1 ]] && {
    printf "%40s%s\n%s\n" "ATTENTION: potential ERROR: Ensure that the restart " \
                    "files have been generated with locosp=T." \
                    "If so, comment out the exit below."
    exit 1; 
 }

if [[ $locosp = true  || $locosp = T ]]; then
tdiag="tdiag"
 else
tdiag=""
fi


#
#-- restart files for ECHAM
#
# restart files for additional CFMIP diagnostics
if [[ $locosp = true || $locosp = T  ]]; then
 tdiagmrest=rerun_${expid}_tdiagm
 tdiagm_restart_file=${atm_restart_dir}/rerun_${pexp}_tdiagm_${odate}${ndate}
 cosprest=rerun_${expid}_cosp 
fi


if [ ${jobnum} != 1 ]; then
  prevdate=`calc_date minus -c${caltype} -D1 -- ${startdate}`
  get_file ${atmmod}  restart  rerun_${expid}_echam_${prevdate} rerun_${expid}_echam
  if [ ${hd:-false} = true ]; then
    get_file ${atmmod} restart rerun_${expid}_hd_${prevdate}.nc hdrestart.nc
  fi
  if [[ ${locosp:-false} = true ]]; then
   get_file ${atmmod}  restart  rerun_${expid}_tdiagm_${prevdate} rerun_${expid}_tdiagm
  fi
  if [[ ${locosp:-false} = T ]]; then
   \cp rerun_${expid}_echam ${tdiagmrest}
  fi
  if [ "${srfmod}" = "jsbach" ]; then
    get_file ${atmmod} restart  rerun_${expid}_co2_${prevdate} rerun_${expid}_co2
  fi
  if [ "${lco2}" = "true" ]; then
    get_file ${atmmod} restart  rerun_${expid}_tracer_${prevdate} \
                                rerun_${expid}_tracer
  fi
elif [ ${atm_restart} = 1 ] ; then
  \cp ${atm_restart_file}    rerun_${expid}_echam
  if [ ${hd:-false} = true ]; then
    \cp ${hd_restart_file}   hdrestart.nc
  fi
  if [ "${srfmod}" = "jsbach" ]; then
    \cp ${atm_restart_co2}     rerun_${expid}_co2
  fi
  if [ "${lco2}" = "true" ]; then
    \cp ${atm_restart_tracer}  rerun_${expid}_tracer
  fi
  if [[ $locosp = true || $locosp = T ]]; then
   if [[ -e ${tdiagm_restart_file} ]]; then
    \cp ${tdiagm_restart_file} rerun_${expid}_tdiagm
   else
     echo "WARNING:  generic restart file for tdiagm"
     if [[ -e  rerun_${expid}_echam  ]]; then
        \cp rerun_${expid}_echam ${tdiagmrest}
     fi
   fi
  fi
fi
if [[ $locosp = true  || $locosp = T  ]]; then
 if [[ -e ./rerun_${expid}_echam ]]; then
  \cp rerun_${expid}_echam ${cosprest}
 fi 
fi
#
#-- input files for JSBACH
#

typeset -Z4 yr0 yp1 ym1 ym2
yr0=$(echo ${startdate} | cut -c1-4)
(( yp1 = yr0 + 1 )); (( ym1 = yr0 - 1 )); (( ym2 = yr0 - 2 ))

eval ${srf_ifiles}

#
#-- restart files for JSBACH
#

prevdate=`calc_date minus -c${caltype} -D1 -- ${startdate}`
if [ ${jobnum} != 1 ]; then
  get_file ${srfmod}  restart  rerun_${expid}_jsbach_${prevdate} rerun_${expid}_jsbach
  get_file ${srfmod}  restart  rerun_${expid}_veg_${prevdate}    rerun_${expid}_veg
  if [ ${atmmod:-NotSet} = NotSet ]; then
    get_file ${srfmod}  restart  rerun_${expid}_forcing_${prevdate} rerun_${expid}_forcing
    get_file ${srfmod}  restart  rerun_${expid}_driving_${prevdate} rerun_${expid}_driving
  else
    get_file ${srfmod}  restart  rerun_${expid}_surf_${prevdate} rerun_${expid}_surf
  fi
elif [ ${srf_restart} = 1 ] ; then
  \cp ${srf_restart_jsbach}  rerun_${expid}_jsbach
  \cp ${srf_restart_veg}     rerun_${expid}_veg
  if [ ${atmmod:-NotSet} = NotSet ]; then
    \cp ${srf_restart_forcing} rerun_${expid}_forcing
    \cp ${srf_restart_driving} rerun_${expid}_driving
  else
    \cp ${srf_restart_surf}    rerun_${expid}_surf
  fi
fi

#
#-- get input files for MPIOM
#

eval  ${oce_ifiles}

#
#-- restart files for MPIOM
#

if [ ${jobnum} = 1 ]; then
  if [ ${oce_restart} = 1 ] ; then
    \cp ${oce_restart_file}         rerun_${expid}_mpiom.nc
  fi
else
  prevdate=`calc_date minus -c${caltype} -D1 -- ${startdate}`
  get_file ${ocemod} restart rerun_${expid}_mpiom_${prevdate}.nc  rerun_${expid}_mpiom.nc
fi

#
#-- get input files for HAMOCC
#

eval       ${bgc_ifiles}

#
#-- restart files for HAMOCC
#

if [ ${jobnum} = 1 ]; then
  if [ ${bgc_restart} = 1 ]; then
    \cp ${bgc_restart_file}   rerun_${expid}_hamocc.nc
  fi
else
  prevdate=`calc_date minus -c${caltype} -D1 -- ${startdate}`
  get_file ${bgcmod} restart rerun_${expid}_hamocc_${prevdate}.nc rerun_${expid}_hamocc.nc
fi

#------------------------------------------------------------------------------
#    PRE - PROCESSING : provide and update configuration files (namelists etc.)
#------------------------------------------------------------------------------

printf "\n%s\n" " |- Provide configuration files (namelists, XML, etc.)"

#------------------------------------------------------------------------------
#-- Namelist OASIS3 (namcouple)
#

#
# runtime: duration of the experiment (seconds)
#
runtime=`time_between -c${caltype} -- ${startdate} ${nextdate} seconds`

#
# startdate in format YYYYMMDD
#
typeset -Z8 yyyymmdd
yyyymmdd=`echo ${startdate#-} | cut -c1-8` 

#
# sequential mode and time lag
#

# both models run seqentially when the experiment is started
if [ ${jobnum} = 1 ] && [ ${cpl_restart} = 0 ]; then
  run_mode=sequential
fi

if [ ${run_mode} = sequential ]; then
  nmseq=2                         # models run sequentially
  lago2a=$nodt
  laga2o=`expr $nadt - $dta2o`
  iseq=2
else
  nmseq=1                         # models run concurrently
  iseq=1
  lago2a=$nodt
  laga2o=$nadt
fi

#
# buffered/simple MPI send
#
if [ ${bsend} = no ]; then
  nobsend="NOBSEND"
else
  nobsend=""
fi

#
# restart filenames for the atmosphere/ocean
#
cnfileaw=flxatmos
cnfileow=sstocean

#
# loctrans
#
loctrans=LOCTRANS

#
# adaptation of the namcouple template
#

ed -s namcouple <<EOF
g/#Nmseq/s/#Nmseq/${nmseq}/
g/#Chan/s/#Chan/${message_passing} ${nobsend}/
g/#Mod1procs/s/#Mod1procs/ ${nprococe} ${ncplprococe} $arg1 /
g/#Mod2procs/s/#Mod2procs/ ${nprocatm} ${ncplprocatm} $arg2 /
g/#Cplexptid/s/#Cplexptid/${jobname}/
g/#Atmmodnam/s/#Atmmodnam/echam6/
g/#Ocemodnam/s/#Ocemodnam/mpiom/
g/#Runtime/s/#Runtime/${runtime}/
g/#Yyyymmdd/s/#Yyyymmdd/${yyyymmdd}/
g/#Nlogprt/s/#Nlogprt/${nlogprt}/
g/#Dta2o/s/#Dta2o/${dta2o}/
g/#Dto2a/s/#Dto2a/${dto2a}/
g/#Iseq/s/#Iseq/${iseq}/
g/#Laga2o/s/#Laga2o/${laga2o}/
g/#Lago2a/s/#Lago2a/${lago2a}/
g/#TimTransa2o/s/#TimTransa2o/${timtransa2o}/
g/#TimTranso2a/s/#TimTranso2a/${timtranso2a}/
g/#Exp/s/#Exp/${export}/
g/#LocTrans/s/#LocTrans/${loctrans}/
g/#Extrapwr/s/#Extrapwr/${extrapwr}/
g/#Cnfileaw/s/#Cnfileaw/${cnfileaw}/
g/#Cnfileow/s/#Cnfileow/${cnfileow}/
w
q
EOF

#-- create/print multiple namcouple files (one for each OASIS3 process)

namcut.sh -n ${nprocoasis} -b namcouple

n=0
while (( n < ${nprocoasis} )); do
  echo "* ----------------------------------------------------------------------"
  echo "* Namelist of OASIS3 instance $n : namcouple_$n"
  echo "* ----------------------------------------------------------------------"
  #cat namcouple_$n
  (( n = n + 1 ))
done

#------------------------------------------------------------------------------
#-- Namelist ECHAM
#

#
#-- set switch for latitude dependent sources of gravity waves (QBO)

if [[ $vres_atm -lt 95 ]]; then
  lrmscon_lat=false
else
  lrmscon_lat=true
fi


#
#-- resumed or initial run?
#
if [[ ${jobnum} = 1 && ${atm_restart} = 0 ]]; then
  rerun=.FALSE.
else
  rerun=.TRUE.
fi

#
#-- coupled or stand-alone run?
#

# initial date of the experiment (with coupled runs: one timestep before
#    midnight)
# Initialisation of the echam time manager can take a long time if the current
# date is far from the initial date of the experiment. To improve this, we set
# the year in dt_start just one year befor the the current date.
# (Setting dt_start to the current date would lead to echam re-initialization!)
#    Note that events that do not occur on a yearly basis will not be treated
#    correctly!

if [[ "${ocemod:-""}" = "" ]]; then
 # stand alone echam
 lcouple=false
 date=$(calc_date minus -c${caltype} -Y${atm_age} -s${nadt} -- ${inidate})
 year=$(format_date -f4 -- ${inidate} | cut -f1 -d" ")
 month_day_time=$(format_date -f4 -s -- ${date} | cut -f2- -d" ")
 dt_year=$(format_date -f4 -- ${date} | cut -f1 -d" ")
 dt_date="${dt_year} ${month_day_time}"
 date="${year} ${month_day_time}"
 dt_start=$(echo ${dt_date} | tr " " ,)
 [[ ${atm_restart} = 0 ]] || dt_start="0000,00,00,00,00,00"
else
 # echam coupled to ocean
 getoff=0
 putoff=-$nadt
 na2ocsteps=$(expr $dta2o / $nadt)
 no2acsteps=$(expr $dto2a / $nadt)
 getocean="$no2acsteps,'steps','exact',$getoff"
 putocean="$na2ocsteps,'steps','exact',$putoff"
 lcouple=true
 date=`calc_date minus -c${caltype} -Y${atm_age} -s${nadt} -- ${inidate}`
 year=`format_date -f4 -- ${startdate} | cut -f1 -d" "`
 if [ ${rerun} = .TRUE. ]; then
   (( year = year - 2 ))
 fi
 if [ ${rerun} = .FALSE. ]; then
   (( year = year - 1 ))
 fi
 month_day_time=$(format_date -f4 -s -- ${date} | cut -f2- -d" ")
 date="${year} ${month_day_time}"
 dt_start=$(echo ${date} | tr " " ,)
fi

#
#-- end date of the run
#
dt_stop=`format_date -f4 -s -- ${nextdate} | tr " " ,`

#
#-- rerun interval
#
if [ ${nmonth} -ne 0 ]; then
  (( nm = 12 * nyear + nmonth )) 
  put_rerun="${nm},'months','last',0"
elif [ ${nyear} -ne 0 ]; then
  put_rerun="${nyear},'years','last',0" 
elif [ ${nday} -ne 0 ]; then
  put_rerun="${nday},'days','last',0"
fi

#
#  modifying namelist parameters during experiment
#  1) for setting disturbance parameter (crashes; realisation)
#  2) for modifying orbital parameters
#
eval $set_enstdif || enstdif=1.0

cat -> namelist.echam << EOF
&parctl
  NPROCA       = ${nproca_atm}
  NPROCB       = ${nprocb_atm}
/
&runctl
  LTIMER         = .${ltimer:-false}.
  LRESUME        = ${rerun}
  OUT_DATAPATH   = './' 
  OUT_EXPNAME    = '${expid}'
  OUT_FILETYPE   = ${atm_out_filetype}
  OUT_ZTYPE      = ${atm_out_ztype}
  RERUN_FILETYPE = 4
  LAMIP          = .${lamip:-false}.
  DT_START       = ${dt_start}
  DT_STOP        = ${dt_stop}
  DELTA_TIME     = ${nadt}.
  PUTDATA        = ${dt_write_atm},'hours','first',0
  PUTRERUN       = ${put_rerun} 
  TRIGFILES      = 1,'months','first',0
  NPROMA         = ${nproma_atm}
  LCOUPLE        = .${lcouple:-false}.
  GETOCEAN       = ${getocean}
  PUTOCEAN       = ${putocean}
  LHD            = .${hd}.
  NHD_DIAG       = ${nhd_diag:-0} 
  LIPCC          = .true.
  NO_CYCLES      = ${no_cycles:-1}
  LMIDATM        = .true.
  LDEBUGEV       = .${ldebugev:-false}.
  LCOUPLE_CO2    = .${lcouple_co2:-false}.
  L_ORBVSOP87    = .${l_orbvsop87:-true}.
/
&dynctl
  ENSTDIF        = ${enstdif:-1.0}
/
&physctl
  LCOVER       = .false.
/
&gwsctl 
  LRMSCON_LAT  = .${lrmscon_lat:-false}. 
/
&submodelctl
  LCO2         = .${lco2:-false}.
  LMETHOX      = .true.
  LTRANSDIAG   = .true.
/
&radctl
  IAERO   = ${iaero:-2}
  IO3     = ${io3:-3}
  IGHG    = ${ighg:-0}
  ISOLRAD = ${isolrad:-3}
  ICFC    = ${icfc:-2}
  ICH4    = ${ich4:-3}
  IN2O    = ${in2o:-3}
  ICO2    = ${ico2:-2}
  CO2VMR  = 339.000000e-6
  CH4VMR  = 1.54700000e-6
  N2OVMR  = 0.30120000e-6
/
&cospctl
  LOCOSP  = .${locosp:-false}.
/
&co2ctl
 LCO2_SCENARIO = .${lco2_scenario:-false}.
/
EOF

# NOTE: The namelist file is created from 
#         nml_echam6_historical-LR
#       in directory .../util/running/adjunct_files/echam6


if [[ $locosp = true  || $locosp = T ]]; then
#
#  write diag.nml for CFMIP tendency output
#
cat ->  tdiag.nml  << EOF
&MVCTL
PUTMEAN = 1,'days','first',0
meannam = 'dqdt_vdiff','dqdt_cucall','dqdt_cloud','dtdt_vdiff','dtdt_cucall','dtdt_cloud','dtdt_rheat_sw','dtdt_rheat_lw','dtdt_hines','dtdt_sso','aps'
/
EOF
fi

echo "* ----------------------------------------------------------------------"
echo "* Namelist of ECHAM: namelist.echam"
echo "* ----------------------------------------------------------------------"
cat namelist.echam
echo "* ----------------------------------------------------------------------"
echo "*    end of namelist.echam"
echo "* ----------------------------------------------------------------------"
echo ""

#
#-- Namelist JSBACH
#

#
# read_fpc / read_cpools
#   false: never read C-pools / fractional plant cover from file
#   true : read C-pools/fpc from file only when the experiment is initialized
#          (jobnum=1 && srf_restart=0) 
#   force: read C-pools during a running experiment to overwrite the values
#          from the restart file (jobnum>1 || srf_restart=1)

if [[ ${jobnum} != 1 || ${srf_restart} = 1 ]] ; then
  [[ ${read_cpools:=false} = true  ]] && read_cpools=false
  [[ ${read_fpc:=false}    = true  ]] && read_fpc=false
fi
[[ ${read_cpools:=false} = force ]] && read_cpools=true
[[ ${read_fpc:=false}    = force ]] && read_fpc=true

init_running_means=false
if [[ ${dynveg} = true && ${srf_restart} = 0 \
   && $(time_between ${inidate} ${startdate} months) -eq 12 ]]; then
  init_running_means=true
fi


cat -> namelist.jsbach <<EOF
&jsbach_ctl
  STANDALONE         = .false.
  NTILES             = ${ntiles}
  USE_BETHY          = .true.
  USE_PHENOLOGY      = .true.
  USE_ALBEDO         = .true.
  USE_DYNVEG         = .${dynveg:-false}.
  WITH_NITROGEN      = .false.
  LCC_FORCING_TYPE   = "${lcc_forcing_type:-none}"
  FILE_TYPE          = "${srf_out_filetype}"
  LPOST_ECHAM        = .${lpost_echam:-false}.
  DEBUG              = .false.
  TEST_CCONSERVATION = .true.
  READ_COVER_FRACT   = .${read_cover_fract:-false}.
/
&cbalance_ctl
  READ_CPOOLS = .${read_cpools:-false}.
  READ_NPOOLS = .${read_npools:-false}.
  READ_NDEPO  = .${read_ndepo:-false}.
/
&dynveg_ctl
  READ_FPC           = .${read_fpc:-false}.
  DYNVEG_FEEDBACK    = .${dynveg_feedback:-true}.
/
&climbuf_ctl
  INIT_RUNNING_MEANS = .${init_running_means:-false}.
/
EOF

# NOTE: The namelist file is created from 
#         nml_jsbach_c5
#       in directory .../util/running/adjunct_files/jsbach

echo "* ----------------------------------------------------------------------"
echo "* Namelist of JSBACH: namelist.jsbach"
echo "* ----------------------------------------------------------------------"
cat namelist.jsbach
echo "* ----------------------------------------------------------------------"
echo "*    end of namelist.jsbach"
echo "* ----------------------------------------------------------------------"
echo ""

#------------------------------------------------------------------------------
#-- Namelist MPIOM
#

#-- to allow test runs with just a few days

if [ ${nday} != 0 ]; then
  nmonts=0
else 
  (( nmonts = ${nyear} * 12 + ${nmonth} ))
fi

#-- restarted run

if [ ${jobnum} != 1 ] || [ ${oce_restart} = 1 ]; then
  istart=3
fi

#-- set start date if initialized

if [[ $oce_restart = 0 ]]; then
  initial_time=$(format_date -f 4 -h -m -s -- "${initial_date}" )
  model_start_time=$(echo $initial_time | tr " " ",")
else
  model_start_time="0,0,0,0,0,0"
fi

#-- codes for fixed (table=fx) parameters; first run only

[[ $jobnum = 1 ]] && fx_codes="84,172,85,86,197"

#-- codes available from a certain revision only

[[ ${oce_src_revision:-0} -ge 4538 && $res_mod = P ]] && {
newCodes_2d_mm=,127,128,134,136
newCodes_3du_mm=,6,135
newCodes_3dw_mm=,110,111,112,214
}

# Global integrals/means (code range 513-519)
GLOBAL=$( z=`seq 513 519` ; echo $z | sed 's/ /,/g;s/.{80}/&\n/g' )

# Section diagnostics (code range 610-815)
SECTIONS=703,644,645,714,715,684,685,$( z=`seq 610 765 | grep -v '[0-1,3-9]$' ;\
         seq 770 815 | grep -v '[3,6-9]$'` ; echo $z | sed 's/ /,/g;s/.{80}/&\n/g' )

# Region diagnostics (code range 820-963)
REGIONS=$( z=`seq 820 963` ; echo $z | sed 's/ /,/g;s/.{80}/&\n/g' )

#
# Namelist for MPIOM
#
cat -> OCECTL << EOF
&OCEDIM
 IE_G=${nx_oce}
 JE_G=${ny_oce}
 KE=${vres_oce}
 lbounds_exch_tp=.false.
/
&NPROCS
 NPROCX=${nproca_oce}
 NPROCY=${nprocb_oce}
/
&OCECTL
 DT            = ${nodt}.
 CAULAPTS      = 0.0000
 CAULAPUV      = 0.006
 IBOLK         = 250
 RTSORPAR      = -999.
 AUS           = 0.
 CAH00         = 1000.
 DV0           = 0.2E-2
 AV0           = 0.2E-2
 CWT           = 0.50E-3
 CWA           = 0.75E-3
 CSTABEPS      = 0.03
 DBACK         = 1.05E-5
 ABACK         = 5.E-5
 CDVOCON       = 0.1
 CAVOCON       = 0.0
 NFIXYEARLEN   = ${nfixYearLen:-"-1"}
 LTIDAL        = .${ltidal:-false}.
 NMONTS        = ${nmonts}
 NDAYS         = ${nday}
 ISTART        = ${istart:-"3"}
 IHALO_SOR     = 2
 IMOD          = 1
 LMPITYPE      = .false.
 LNONBLOCK     = .true.
 ICONTRO       = 0
 LUNDELAYED_MOMENTUM_ADVECTION = .false.
 RLEADCLOSE       = 0.25,3.0,2.0
 H0               = 0.5
 ITER_SOR         = 300
 LSWR_JERLOV      = .true.
 JERLOV_ATTEN     = 0.06    ! jerlov IA
 JERLOV_BLUEFRAC  = 0.41    ! jerlov IA
 ITER_SOR_HACK    = 0
 RTSORPAR_HACK    = -999.
 LSAOCLOSE        = .true.
 LZO_CORRECT      = .false.
 LAKES            = .false.
/
&OCEDZW
 CDZW = 12.,10.,10.,10.,10.,10.,13.,15.,20.,25.
       ,30.,35.,40.,45.,50.,55.,60.,70.,80.,90.
      ,100.,110.,120.,130.,140.,150.,170.,180.,190.,200.
      ,220.,250.,270.,300.,350.,400.,450.,500.,500.,600.
/
&IOCTL
  IOLIST(1) = 99, 'rerun_${expid}_mpiom.nc', 'nc4',
               1,2,3,4,5,7,9,10,13,15,35,36,82,84,99,
               110,111,141,501,502,503,504
  IOLIST(21) = 2, '${expid}_mpiom_data_2d_mm.nc','nc2',
               1,11,12,13,14,15,16,17,27,
               70,79,123,124,125,126,127,128,134,136,138,139,141,149,150,181,183,
               215,216,217,218,219,220,221,222,223,224,226,227,228,229
  IOLIST(22) = 1, '${expid}_mpiom_data_2d_dm.nc','nc2',
               12,13,14,15,37,38,182
  IOLIST(23) = 1, '${expid}_mpiom_timeser_dm.nc', 'nc2',
               ${GLOBAL}, ${SECTIONS}, ${REGIONS},
               93,94,95,96,97,98,100,101,102
  IOLIST(24) = 3, '${expid}_mpiom_monitoring_ym.nc', 'nc2',
               518,622,652,672,703,800,836,837,900,901,
               936,950,951,952,953,955,956,958,959,961,962,101
  IOLIST(25) = 2, '${expid}_mpiom_data_3du_mm.nc','nc2',
               2,3,4,5,6,18,23,24,135,197
  IOLIST(26) = 2, '${expid}_mpiom_data_3dw_mm.nc','nc2',
               21,22,110,111,112,214
  IOLIST(27) = 303, '${expid}_mpiom_data_fx.nc','nc2',
               ${fx_codes:-""}
/
&forcctl
/
EOF

# The namelist file is created from 
#		nml_mpiom_c5-LR
# in .../util/running/adjunct_files/mpiom

echo "* ----------------------------------------------------------------------"
echo "* Namelist of MPIOM: OCECTL"
echo "* ----------------------------------------------------------------------"
cat OCECTL
echo "* ----------------------------------------------------------------------"
echo "*    end of OCECTL"
echo "* ----------------------------------------------------------------------"
echo ""



#
#-- Namelist for HAMOCC
#
(( steps_per_day = 86400 / nbdt ))
cat > NAMELIST_BGC  << EOF
&BGCCTL
 DELTACALC    = 900.0
 DELTAORG     =  0.0
 DELTASIL     = 200.0
 IO_STDO_BGC  =  8
 KCHCK        =  0
 ISAC         =  1
 MEAN_2D_FREQ =  0
 MEAN_3D_FREQ =  0
 RMASKO       = -9e33
 INVRESET     = .false.
 LSPINBGC     = .false.
 FSPINBGC     = 1.0
/
&ioctl
  IOLIST(1)=99,'rerun_${expid}_hamocc.nc','nc4',
     7,10,11,12,13,14,15,16,17,20,21,22,23,24,27,28,29,30,31,37,38,
     41,44,45,46,47,48,49,50,51,54,55,56,57,58,59,60,61,62,64,203,204,205
  IOLIST(24)=2,'${expid}_hamocc_data_2d_mm.nc','nc2',
     67,68,72,75,78,81,92,93,94,95,
     107,110,111,112,114,115,116,117,120,121,122,123,124,127,129,131,137,
     157,159,160,161,162,163,164,165,185,186,200,206,207,210,211,214,215,231
  IOLIST(30) = 101,'${expid}_hamocc_co2.nc','nc2',
     301,303,304,305,306,307,308,309,310,311,312,313,314
  IOLIST(31)=3,'${expid}_hamocc_monitoring_ym.nc','nc2',
     500,501,502,503,504,505,506,507
  IOLIST(25) = 2,'${expid}_hamocc_sedi_mm.nc','nc2',
     38,41,44,45,46,47,48,49,50,51,54,55,56,57,58,59,60,
     94,95,96,97,280,281,282,283,284,285,286,287
/
&END
EOF

# The namelist file is created from 
#		nml_hamocc_c5-LR
# in .../util/running/adjunct_files/hamocc

echo "* ----------------------------------------------------------------------"
echo "* Namelist of HAMOCC: NAMELIST_BGC"
echo "* ----------------------------------------------------------------------"
cat NAMELIST_BGC
echo "* ----------------------------------------------------------------------"
echo "*    end of NAMELIST_BGC"
echo "* ----------------------------------------------------------------------"
echo ""

#------------------------------------------------------------------------------
#
#     5. LAUNCHING THE MODEL
#
#------------------------------------------------------------------------------

printf "List of files in working directory \n$(pwd) \nat $(date):\n"; ls -al

# Create a test file for script .../functions/save_file
mv ${jobdir}/out_* ${logdir} || echo "no old log files. "


echo "The date of the output files is compared to the date of this file" \
	  > reference_file

###############################################################################
#
# Environment variables for the Parallel Operating Env. (poe)
#  (see http://www.dkrz.de/dkrz/services/P6_docs/P6-howto8_en_US.html
#    for details)
#
###############################################################################
#
# debug options
#


export MPICH_MAX_SHORT_MSG_SIZE=960000 # default is 128000 bytes
export MPICH_PTL_UNEX_EVENTS=90000 # default is  90000 (unexpected recv queue size)
export MPICH_UNEX_BUFFER_SIZE=600M # default is    60M (unexpected short msgs buff size)
#setenv MPICH_MSGS_PER_PROC      160000 # default is  32768
export MPICH_MSGS_PER_PROC=160000 # default is  32768
export MPICH_PTL_SEND_CREDITS=-1
export I_MPI_COMPATIBILITY=3
export MPICH_ENV_DISPLAY=1
export MPICH_VERSION_DISPLAY=1


# These environment variables were suggested by Helen He to help get around compiler issues
export MALLOC_MMAP_MAX_=0
export MALLOC_TRIM_THRESHOLD_=536870912

# The environment variables below produce corefiles and maybe (?) should be
# moved to DEBUG mode at some point
export MPICH_DBMASK=0x200
export decfort_dump_flag=Y
#limit coredumpsize unlimited
#limit stacksize unlimited

# The environment variable below increase the stack size, which is necessary for
# CICE to run threaded on this machine.  
#setenv KMP_STACKSIZE 64M

#
OMP_NUM_THREADS=${OMP_NUM_THREADS:-1}; export OMP_NUM_THREADS

ulimit -c 0   # size of core dumps, in number of 512-byte blocks

#
###############################################################################

###############################################################################

message_passing=${message_passing}

cd ${work}/${expid}/work
set -ex
export LID="`date +%y%m%d_%H%M%S`"
outlogfile=${jobdir}/out_${expid}_log_$LID
outerrfile=${jobdir}/out_${expid}_err_$LID


    printf "\n%s\n" " |------------------------------------------------------|"
    printf "%s\n"   " |- Model launched at \$(date)                           "
    printf "%s\n\n" " |------------------------------------------------------|"
 
print "\n |-------------------------------|\n |- $(date) |"
print " |- Launch the model ${cplmod} |\n |-------------------------------|\n"

    rm -f mpmd.lst
    n=0
    echo "${n} ./${cplexec}" >> mpmd.lst
    (( n1 = n + 1 ))
    (( n2 = n1 + nprococe -1 ))
    echo "${n1}-${n2} ./${oceexec}" >> mpmd.lst

    (( n1 = n2 + 1 ))
    (( n2 = n1 + nprocatm -1 ))
    echo "${n1}-${n2} ./${atmexec}" >> mpmd.lst

    paffopt="--multi-prog"
 time  ${MPIBIN} ${paffopt} mpmd.lst  1> ${outlogfile} 2> ${outerrfile}  || {
     printf "\n%s\n" " |-----------------------------------------------------|"
     printf "%s\n"   " |- ERROR in model integration                          "
     printf "%s\n"   " |- Model run aborted at \$(date)                       "
     printf "%s\n\n" " |-----------------------------------------------------|"


  ls -lta
  exit 1
  }

print "\n |-------------------------------|\n |- $(date) |"
print " |- Model integration completed  |\n |-------------------------------|\n"




if [[ -s ERROR.ctl ]]; then
  printf "%s\n%s\n" "An ERROR has been detected during model integration." \
                    "   ==> The script is stopped."
  RUN_status=1; wait; exit 1
else
  #-- Generate profiling protocol
  if [ -f  *.${oceexec} ]; then
    echo 'Profiling '${oceexec}' ...'
    ${cp} *.${oceexec} ${logdir}/${oceexec}.mon.out
    ${cp} *.${oceexec} mon.out
    prof ${oceexec}
  fi
  if [ -f  *.${atmexec} ]; then
    echo 'Profiling '${atmexec}' ...'
    ${cp} *.${atmexec} ${logdir}/${atmexec}.mon.out
    ${cp} *.${atmexec} mon.out
    prof ${atmexec}
  fi
  if [ -f  *.${cplexec} ]; then
    echo 'Profiling '${cplexec}' ...'
    ${cp} *.${cplexec} ${logdir}/${cplexec}.mon.out
    ${cp} *.${cplexec} mon.out
    prof ${cplexec}
  fi

fi  

###############################################################################
#
# Start raw output saving ...
#
###############################################################################

#-- Definition of some time variables

# enddate:      last day of this run
# prevdate:     last day of the previous run 
# startyear:    year at the beginning of this run
# prevyear:     year at the last day of the previous run
# prevdecade:   decade at the last day of the previous run
# previd:       job-id of the previous run (from expid.log)

enddate=$(calc_date minus -c${caltype} -D1 -- ${nextdate})
prevdate=$(calc_date minus -c${caltype} -D1 -- ${startdate})
startyear=$(format_date -f4 -- ${startdate} | cut -f1 -d" ")
prevyear=$(format_date -f4 -- ${prevdate} | cut -f1 -d" ")
prevdecade=${prevyear%?}

if [[ -r ${jobdir}/${expid}.log ]];then
  loginfo=$(get_logpid -d ${startdate} -f ${jobdir}/${expid}.log)
  if [[ -n ${loginfo} ]];then
    previd=${loginfo%[ ]*}
    prevstart=${loginfo#*[ ]}
  else
    printf "%s%s\n" "   |- WARNING : Can not find message for ${startdate}" \
                    " in" "      ${jobdir}/${expid}.log"
    previd=
    prevstart=${startdate}
  fi
else
  printf "   |- WARNING : Can not access log file \n\t\t${jobdir}/${expid}.log\n"
  printf "   |            log files of previous run can not be archived !\n\n"
fi

###############################################################################
# 
#  Save output of OASIS3 ( do not save input ! )
#
###############################################################################

wait
printf "\n%s\n\t\t%s\n\t\t%s\n\n" "+++++ Save OASIS3 output and restart files"\
       " from   ${work}/'expid'/work" " to     $data/'expid'"

cd ${work}/${expid}/work; wait

SAVE_status=${SAVE_status:=0}

#-- output files of OASIS

files=$(ls ????????_out.????-??-??T??:??:??.nc 2>/dev/null) || { files=""; }
for file in ${files}; do
  save_file ${coupler} output ${file} &
done

#-- log files of OASIS

files=$(ls cplout* Oasis.prt* 2>/dev/null) || { files=""; }
for file in ${files}; do
    save_file ${coupler} log $file ${file}_${enddate} &
done

#-- restart files of OASIS

status=0; tar -cf sstocean_${expid}_${enddate}.tar sstoce[1-9]* || status=1
if [[ ${status} = 1 ]]; then
  SAVE_status=${SAVE_status}sstoce
else
  save_file ${coupler} restart sstocean_${expid}_${enddate}.tar &
fi

status=0; tar -cf flxatmos_${expid}_${enddate}.tar flxatm[1-9]* || status=1
if [[ ${status} = 1 ]]; then
  SAVE_status=${SAVE_status}flxatm
else
  save_file ${coupler} restart flxatmos_${expid}_${enddate}.tar &
fi

###############################################################################
#
#  Save output of ECHAM
#
###############################################################################

wait
printf "\n%s\n\t\t%s\n\t\t%s\n\n" "+++++ Save ECHAM output and restart files" \
       " from   ${work}/'expid'/work" " to     $data/'expid'"

suff=.grb; [[ "${atm_out_ztype}" = "1" ]] && suff=.sz
cd ${work}/${expid}/work; wait

SAVE_status=${SAVE_status:="0"}

#-- raw diagnostic output, code lists (first run only), and restart files 

#-- ECHAM output streams
substreams="echam co2" # default streams
[[ "${lco2}" = "true" ]] && substreams="${substreams} tracer" # tracer
#- additional CFMIP output
if [[ ${locosp:-false} = true ]]; then # Warning: no saving if locosp=T !
  substreams="${substreams} tdiagm tdiag cfdiag"
fi

for substream in ${substreams};do
  date=${startdate}
  while [[ $(later_date -- ${date} ${enddate}) = ${enddate} ]]; do
    year=$(format_date  -f4 -- ${date} | cut -f1 -d" ")
    month=$(format_date -f4 -- ${date} | cut -f2 -d" ")
    day=$(format_date   -f4 -- ${date} | cut -f3 -d" ")
    ym=${year}${month}
    if [ -r ${expid}_${ym}.${day}_${substream} ]; then
      save_file ${atmmod} output ${expid}_${ym}.${day}_${substream} \
                                 ${expid}_${atmmod}_${substream}_${ym}${suff} &
    else
      SAVE_status=${SAVE_status}/echam:${substream}${month}
    fi
    #-- hydrology output files
    if [ -r ${expid}_${ym}.${day}_hd_higres.nc ]; then
      save_file ${atmmod} output ${expid}_${year}01.${day}_hd_higres.nc \
                                 ${expmod}_hd_higres_${startdate}.nc &
    fi
    date=$(calc_date plus -c${caltype} -M1 -- ${date})
  done # months
  if [[ ${jobnum} = 1 ]]; then
    if [ -r ${expid}_${startyear}01.${day}_${substream}.codes ]; then
      save_file ${atmmod} log ${expid}_${startyear}01.${day}_${substream}.codes \
                              ${expid}_${atmmod}_${substream}.codes &
    else
      SAVE_status=${SAVE_status}/echam:codes:${substream}
    fi
  fi
  if [[ -r rerun_${expid}_${substream} ]]; then
    save_file ${atmmod} restart rerun_${expid}_${substream} \
                                rerun_${expid}_${substream}_${enddate} &
  else
    if [[ ${substream} != tdiag ]] && [[ ${substream} != cfdiag ]];then 
      SAVE_status=${SAVE_status}/echam:rerun:${substream}
    fi
  fi
done # substreams

#-- Additional CFMIP output (cfSites)
if [[ ${locosp:-false} = true ]]; then     # Warning: no saving if locosp=T !
  date=${startdate}
  while [[ $(later_date -- ${date} ${enddate}) = ${enddate} ]]; do
    year=$(format_date  -f4 -- ${date} | cut -f1 -d" ")
    month=$(format_date -f4 -- ${date} | cut -f2 -d" ")
    day=$(format_date   -f4 -- ${date} | cut -f3 -d" ")
    ym=${year}${month}
    if [[ -r ${expid}_${ym}.${day}_cfSites0000 ]]; then
      tar czvf ${expid}_${ym}.${day}_cfSitesAll.tar.gz ${expid}_${ym}.${day}_cfSites????  
      if [[ -r  ${expid}_${ym}.${day}_cfSitesAll.tar.gz  ]]; then
       save_file ${atmmod}  output  ${expid}_${ym}.${day}_cfSitesAll.tar.gz  ${expid}_${atmmod}_cfSitesAll_${ym}.tar.gz
      else
        SAVE_status=${SAVE_status}/echam:cfSitesAll${month}
      fi
    fi

  date=$(calc_date plus -c${caltype} -M1 -- ${date})
 done # months
fi  # locosp

#-- CFMIP code files 
if [[ ${locosp_prev:-false} = T ]]; then  
  cfsubstreams="tdiag tdiagm cfdiag"
  for cfsubstream in ${cfsubstreams};do
    if [ -r ${expid}_${startyear}01.${day}_${cfsubstream}.codes ]; then
      save_file ${atmmod} log \
         ${expid}_${startyear}01.${day}_${cfsubstream}.codes \
         ${expid}_${atmmod}_${cfsubstream}.codes &
    fi
  done 
fi # code files

#-- NetCDFC streams: energy transport diagnostic and COSP files
date=${startdate}
while [[ $(later_date -- ${date} ${enddate}) = ${enddate} ]]; do
  year=$(format_date  -f4 -- ${date} | cut -f1 -d" ")
  month=$(format_date -f4 -- ${date} | cut -f2 -d" ")
  day=$(format_date   -f4 -- ${date} | cut -f3 -d" ")
  ym=${year}${month}
  if [[ -r ${expid}_${ym}.${day}_trdiag.nc ]]; then
    save_file ${atmmod} output ${expid}_${ym}.${day}_trdiag.nc \
                            ${expid}_${atmmod}_trdiag_${ym}.nc &
  else
    SAVE_status=${SAVE_status}/echam:trdiag${month}
  fi
  if [[ ${locosp:-false} = true ]]; then     # Warning: no saving if locosp=T !
    if [[ -r ${expid}_${ym}.${day}_cosp.nc ]]; then
      save_file ${atmmod} output ${expid}_${ym}.${day}_cosp.nc \
                              ${expid}_${atmmod}_cosp_${ym}.nc &
    else
      SAVE_status=${SAVE_status}/echam:cosp${month}
    fi
  fi
  date=$(calc_date plus -c${caltype} -M1 -- ${date})
done # months

#-- std output

if [[ "$lcouple" = true ]]; then
 if [[ -r atmout ]]; then
  save_file ${atmmod} log atmout \
            ${expid}_${atmmod}_atmout_${startdate}_${enddate} &
 else
  SAVE_status=${SAVE_status}/echam:atmout
 fi
fi

#-- COSP restart files
if [[ ${locosp:-false} = T ]]; then
  if [[ -r rerun_${expid}_tdiagm ]]; then
    save_file ${atmmod} restart rerun_${expid}_tdiagm \
                                rerun_${expid}_tdiagm_${enddate} &
  else
     SAVE_status=${SAVE_status}/echam:rerun:tdiagm
  fi
fi


#-- hydrology restart files

if [ $hd = true ]; then
  if [[ -r hdrestart.nc ]]; then
    save_file ${atmmod} restart hdrestart.nc rerun_${expid}_hd_${enddate}.nc &\
  else
    SAVE_status=${SAVE_status}/echam:hdrestart
  fi
fi


################################################################################
#
#  Save output of JSBACH
#
################################################################################

wait
printf "\n%s\n\t\t%s\n\t\t%s\n\n" "+++++ Save JSBACH output and restart files" \
       " from   ${work}/'expid'/work" " to     $data/'expid'"

suff=.grb
[[ "${atm_out_ztype}" = "1" ]] && suff=.sz

cd ${work}/${expid}/work; wait

SAVE_status=${SAVE_status:="0"}

substreams="jsbach land veg surf"

if [ ${jobnum} = 1 ]; then
 for substream in ${substreams};do
  if [ -r ${expid}_${startyear}01.01_${substream}.codes ]; then 
    save_file ${srfmod} log ${expid}_${startyear}01.01_${substream}.codes   \
                            ${expid}_${srfmod}_${substream}.codes &
  else
    SAVE_status=${SAVE_status}/jsbach:codes:${substream}
  fi
 done
fi

#-- save JSBACH raw output and restart files

substreams="jsbach land veg surf"
 
for substream in ${substreams};do
  [[ "${substream}" = "jsbach" ]] && datastream=${expid}_${srfmod} || \
    datastream=${expid}_${srfmod}_${substream}
  date=${startdate}
  while [[ $(later_date -- ${date} ${enddate}) = ${enddate} ]]; do
    year=$(format_date -f4  -- ${date} | cut -f1 -d" ")
    month=$(format_date -f4 -- ${date} | cut -f2 -d" ")
    day=$(format_date -f4   -- ${date} | cut -f3 -d" ")
    ym=${year}${month}
    if [ -r ${expid}_${ym}.${day}_${substream} ]; then
      save_file ${srfmod} output ${expid}_${ym}.${day}_${substream} \
                                 ${datastream}_${ym}${suff} &
    else
      SAVE_status=${SAVE_status}/jsbach:${substream}${month}
    fi
    date=$(calc_date plus -c${caltype} -M1 -- ${date})
  done # months
  [[ "$substream" = "land" ]] || {
    if [ -r rerun_${expid}_${substream} ]; then
      save_file ${srfmod} restart  rerun_${expid}_${substream} \
                                   rerun_${expid}_${substream}_${enddate} &
    else
      SAVE_status=${SAVE_status}/jsbach:rerun:${substream}
    fi;}
done          # datastreams

################################################################################
#
#  Save output of MPIOM
#
################################################################################

wait
printf "\n%s\n\t\t%s\n\t\t%s\n\n" "+++++ Save MPIOM output and restart files" \
       " from   ${work}/'expid'/work" " to     $data/'expid'"

suff=.${oce_out_filetype}
cd ${work}/${expid}/work; wait

SAVE_status=${SAVE_status:="0"}

#-- time series

outfile=${expid}_mpiom_timeser_dm.nc
outfile_save=${expid}_mpiom_timeser_dm_${startdate}_${enddate}.nc
if [ -r  ${outfile} ]; then
   save_file ${ocemod} output ${outfile} ${outfile_save} &
else
   SAVE_status=${SAVE_status}/mpiom:timeser
fi

#-- monitoring

outfile=${expid}_mpiom_monitoring_ym.nc
outfile_save=${expid}_mpiom_monitoring_ym_${startdate}_${enddate}.nc
if [ -r  ${outfile} ]; then
   save_file ${ocemod} output ${outfile} ${outfile_save} &
fi

#-- 3D and 2D raw diagnostic output: GRIB

substreams="data_2d_mm data_3du_mm data_3dw_mm data_2d_dm"
for substream in ${substreams}; do
  outfile=${expid}_mpiom_${substream}${suff}
  outfile_save=${expid}_mpiom_${substream}_${startdate}_${enddate}${suff}
  if [ -r  ${outfile} ]; then
    save_file ${ocemod} output ${outfile} ${outfile_save} &
  else
    SAVE_status=${SAVE_status}/mpiom:${substream}
  fi
done

#-- restart files

if [[ -r rerun_${expid}_mpiom.nc ]]; then
  save_file ${ocemod} restart \
    rerun_${expid}_mpiom.nc rerun_${expid}_mpiom_${enddate}.nc &
else
    SAVE_status=${SAVE_status}/mpiom:rerun
fi

#-- std output

if [[ -r oceout ]]; then
 save_file ${ocemod} log oceout ${expid}_mpiom_oceout_${startdate}_${enddate} &
else
 SAVE_status=${SAVE_status}/mpiom:oceout
fi

#-- output parameter table and fixed fields (first run only)

if [[ ${jobnum} = 0 ]]; then
  if [[ -r ${exphome}/work/mpiom.partab ]];then
    save_file ${ocemod} log mpiom.partab &
  else
    SAVE_status=${SAVE_status}/mpiom:partab
  fi
  if [[ -r  ${exphome}/work/${expid}_mpiom_data_fx${suff} ]]; then
    save_file ${ocemod} output ${expid}_mpiom_data_fx${suff} &
  else
    SAVE_status=${SAVE_status}/mpiom:fx
  fi
fi


###############################################################################
#
# Save output of HAMOCC
#
###############################################################################

wait
printf "\n%s\n\t\t%s\n\t\t%s\n\n" "+++++ Save HAMOCC output and restart files" \
       " from   ${work}/'expid'/work" " to     $data/'expid'"

cd ${work}/${expid}/work; wait

SAVE_status=${SAVE_status:="0"}

#-- time series 

outfile=${expid}_hamocc_co2.nc
outfile_save=${expid}_hamocc_ico2_${startdate}_${enddate}.nc
if [ -r  ${outfile} ]; then
  save_file ${bgcmod} output ${outfile} ${outfile_save} &
else
  SAVE_status=${SAVE_status}/hamocc:co2
fi

#-- raw diagnostic output

#substreams="data_3d_ym data_0-100m_ym data_2d_mm eu_data_mm 3d_data_mm sedi_mm"
substreams="data_2d_mm"
for substream in ${substreams}; do
  outfile=${expid}_hamocc_${substream}.nc
  outfile_save=${expid}_hamocc_${substream}_${startdate}_${enddate}.nc
  if [ -r  ${outfile} ]; then
    save_file ${bgcmod} output ${outfile} ${outfile_save} &
  else
    SAVE_status=${SAVE_status}/hamocc:${substream}
  fi
done

#-- monitoring

outfile=${expid}_hamocc_monitoring_ym.nc
outfile_save=${expid}_hamocc_monitoring_ym_${startdate}_${enddate}.nc
if [ -r  ${outfile} ]; then
  save_file ${bgcmod} output ${outfile} ${outfile_save} &
fi

#-- restart files

outfile=rerun_${expid}_hamocc.nc
outfile_save=rerun_${expid}_hamocc_${enddate}.nc
if [[ -r rerun_${expid}_hamocc.nc ]]; then
  save_file ${bgcmod} restart ${outfile} ${outfile_save} &
else
  SAVE_status=${SAVE_status}/hamocc:rerun
fi

#-- std output

if [[ -r bgcout ]]; then
  save_file ${bgcmod} log bgcout ${expid}_hamocc_bgcout_${startdate}_${enddate} &
else
  SAVE_status=${SAVE_status}/hamocc:bgcout
fi

#-- output parameter table

if [[ ${jobnum} = 0 ]]; then
  if [[ -r ${exphome}/work/hamocc.partab ]];then
    cp ${exphome}/work/hamocc.partab ${exphome}/log/hamocc.partab &
  else
    SAVE_status=${SAVE_status}/hamocc:partab
  fi
fi

#------------------------------------------------------------------------------
#
# Check whether model integration finished successfully
#
#------------------------------------------------------------------------------
wait

year=$(format_date  -f4 -- ${date} | cut -f1 -d" ")
[[ "${groupwrite:-no}" = "no" ]] || { 
  chmod g+wx ${jobdir}/*.arch*${year}* ${jobdir}/*.post*${year}* \
             ${jobdir}/*.mon*${year}* || true ; }
## */

if [[ ${RUN_status:-0} = 0 ]]; then
  printf "\n    |+ The model integration run finished successfully\n"
  if [[ ${SAVE_status:-0} = 0 ]]; then
    printf "\n    |+ All existing output files have been saved.\n"
  else
    printf "\n%s\n\n" \
         "      |- ERROR in file saving: SAVE_status = ${SAVE_status}"
    exit 1
  fi
else
  printf "\n%s\n\n" \
         "      |- ERROR occured: RUN_status = ${RUN_status}"
  if [[ ${SAVE_status:-0} = 0 ]]; then
    printf "\n    |+ All existing output files have been saved.\n"
  else
    printf "\n%s\n\n" \
         "      |- ERROR in file saving: SAVE_status = ${SAVE_status}"
  fi
  exit 1
fi

#------------------------------------------------------------------------------
#
#     8. SUBMISSION OF THE NEXT JOB
#
#------------------------------------------------------------------------------
cd  ${jobdir}

#
# Number of the next job
#

(( nextjob = ${jobnum} + 1 ))

#
# edit .date and .log file
#

space_error="no"

echo "${nextdate} ${nextjob}" > ${expid}.date.new || { 
  space_error="yes"; echo "Could not create ${expid}.date"; 
}
cp ${expid}.log ${expid}.log.new || { 
  space_error="yes"; echo "Could not save ${expid}.log"; 
}
echo "$(date +"${datefmt}") :  ${jobnum} ${nextdate} ${jobid}  - done" >> ${expid}.log.new || {
  space_error="yes"; echo "Could not append to ${expid}.log"; 
}

if [ "${space_error}" = "no" ]; then
  mv ${expid}.date.new ${expid}.date
  mv ${expid}.log.new ${expid}.log
  [[ "${groupwrite:-no}" = "no" ]] || { chmod g+wx ${expid}.date ${expid}.log || \
     printf "%s\n" "Problems occured with chmod on date/log files."; }
else
  echo "No disk space left or quota exceeded?"
  echo " - Show quota"
  quota
  exit
fi

#
# Check whether final date is reached
#

if [[ `later_date -- ${nextdate} ${findate}` = ${nextdate} ]]; then
  printf "\n%s\n" "    |+ Experiment over"
  echo "$(date +"${datefmt}") :  Experiment over" >> ${expid}.log
  chmod g-w ${outdir}/*/*.grb ${outdir}/*/*.nc || true
else
  sbatch ${job}
fi

###############################################################################
#
#-- update run dates and submit expid.post script
#
cd ${jobdir}

#cp ${expid}.post  ${expid}.post.${nextdate}

#ed -s ${expid}.post.${nextdate} <<EOF
#1,100s/Jobnum/${jobnum}/
#1,100s/Startdate/${startdate}/
#1,100s/Nextdate/${nextdate}/
#1,100s/Inidate/${inidate}/
#1,100s/Findate/${findate}/
#w
#q
#EOF

if ( [ "post" = "post" ] || [ "post" = "arch" ] ) && [ -e ${home}/${expid}/scripts/.lock_postprocessing ]; then
   print "   |- "
   print "   |- ERROR : next job ${expid}.post.${nextdate} is not submitted, because"
   print "   |- ERROR : previous postprocessing job is terminated by an error."
   print "   |- ERROR : see lock file:  ${home}/${expid}/scripts/.lock_postprocessing"
   print "   |- "
else
  echo skip post
#   sbatch ${expid}.post.${nextdate}
fi
###############################################################################
#
#-- update run dates and submit expid.mon script
#
cd ${jobdir}

#cp ${expid}.mon  ${expid}.mon.${nextdate}

#ed -s ${expid}.mon.${nextdate} <<EOF
#1,100s/Jobnum/${jobnum}/
#1,100s/Startdate/${startdate}/
#1,100s/Nextdate/${nextdate}/
#1,100s/Inidate/${inidate}/
#1,100s/Findate/${findate}/
#w
#q
#EOF

if ( [ "mon" = "post" ] || [ "mon" = "arch" ] ) && [ -e ${home}/${expid}/scripts/.lock_postprocessing ]; then
   print "   |- "
   print "   |- ERROR : next job ${expid}.mon.${nextdate} is not submitted, because"
   print "   |- ERROR : previous postprocessing job is terminated by an error."
   print "   |- ERROR : see lock file:  ${home}/${expid}/scripts/.lock_postprocessing"
   print "   |- "
else
#   qsub  ${expid}.mon.${nextdate}
  echo "skip mon"
fi
#------------------------------------------------------------------------------
#   EPILOGUE
#------------------------------------------------------------------------------

wait; ${job_account}

printf "\n%s\t%s\n"  " End of script at " "$(date +'%b %d %T') on $(hostname)"



exit


